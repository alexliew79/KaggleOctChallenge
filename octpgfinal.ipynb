{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n#Ignore Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-11-07T05:27:30.328199Z","iopub.execute_input":"2021-11-07T05:27:30.328938Z","iopub.status.idle":"2021-11-07T05:27:30.338586Z","shell.execute_reply.started":"2021-11-07T05:27:30.328897Z","shell.execute_reply":"2021-11-07T05:27:30.337796Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# explore the algorithm wrapped by RFE\n#from sklearn.feature_selection import RFE\n#from sklearn.feature_selection import RFECV\nfrom sklearn.feature_selection import SelectKBest\n\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\n\nfrom sklearn.feature_selection import chi2\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import mutual_info_classif\n\n#Calculate Accuracy\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.decomposition import PCA\nfrom sklearn import preprocessing\n\n#Stat test\nfrom scipy.stats import f_oneway\nfrom scipy.stats import ttest_ind\n\nfrom pprint import pprint\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport scipy.stats as stats\n\nfrom matplotlib import pyplot\n\nimport matplotlib.pylab as plt\n%matplotlib inline\n\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize'] = 12, 8\n\n#This is similar to pd.DataFrame\nimport dask.dataframe as dd\n\n#This is an API to call for local Dask Cluster\nfrom dask.distributed import Client, LocalCluster\n","metadata":{"execution":{"iopub.status.busy":"2021-11-07T05:27:32.257454Z","iopub.execute_input":"2021-11-07T05:27:32.258110Z","iopub.status.idle":"2021-11-07T05:27:35.156762Z","shell.execute_reply.started":"2021-11-07T05:27:32.258056Z","shell.execute_reply":"2021-11-07T05:27:35.155933Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#Function to reduce memory usage\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64','float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                else:\n                    df[col] = df[col].astype(np.float32)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df\n\n# feature selection with score_func indicated\ndef select_features(X_train, y_train, score_func):\n    # configure to select all features\n\tfs = SelectKBest(score_func=score_func, k='all')\n\t# learn relationship from training data\n\tfs.fit(X_train, y_train)\n\t# transform train input data\n\tX_train_fs = fs.transform(X_train)\n\t\n\treturn X_train_fs, fs\n ","metadata":{"execution":{"iopub.status.busy":"2021-11-07T03:04:45.832966Z","iopub.execute_input":"2021-11-07T03:04:45.833552Z","iopub.status.idle":"2021-11-07T03:04:45.848784Z","shell.execute_reply.started":"2021-11-07T03:04:45.833513Z","shell.execute_reply":"2021-11-07T03:04:45.847930Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#Taking 2 samples from dataset for training and validation\ntrain_sample = reduce_mem_usage(pd.read_csv(\"../input/tabular-playground-series-oct-2021/train.csv\", nrows=10000))\n#train = reduce_mem_usage(pd.read_csv(\"train.csv\", nrows=10000))\ntest_sample = reduce_mem_usage(pd.read_csv(\"../input/tabular-playground-series-oct-2021/test.csv\", nrows=10000))","metadata":{"execution":{"iopub.status.busy":"2021-11-07T03:04:47.602868Z","iopub.execute_input":"2021-11-07T03:04:47.603462Z","iopub.status.idle":"2021-11-07T03:04:49.927812Z","shell.execute_reply.started":"2021-11-07T03:04:47.603423Z","shell.execute_reply":"2021-11-07T03:04:49.926138Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#Base assumption is I can infer to the population with samples.\n#Pull a sample from the data and sub sample to see if it makes \n#sense.\n\nrow = list()\nmeans = list()\nn=1000\n\nfor count in range(1,n):\n        row.append(count)\n        means.append(train_sample.sample(n=500).target.mean())\ncurve = pd.Series(means,index=row)\n\nfor count in range(1,n):\n        row.append(count)\n        means.append(train_sample.sample(n=100).target.mean())\ncurve2 = pd.Series(means,index=row)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-07T03:04:57.523921Z","iopub.execute_input":"2021-11-07T03:04:57.524661Z","iopub.status.idle":"2021-11-07T03:04:59.059504Z","shell.execute_reply.started":"2021-11-07T03:04:57.524619Z","shell.execute_reply":"2021-11-07T03:04:59.058803Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#Check if train db outcome can be infer with test \npop_mean = train_sample.target.mean()\nstats.ttest_1samp(curve, pop_mean)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T03:04:59.060865Z","iopub.execute_input":"2021-11-07T03:04:59.061119Z","iopub.status.idle":"2021-11-07T03:04:59.073767Z","shell.execute_reply.started":"2021-11-07T03:04:59.061086Z","shell.execute_reply":"2021-11-07T03:04:59.072521Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#null hypothesis is that they are equal, alternative is they are not.\ndef plot_distribution(inp, n=0):\n    plt.figure()\n    ax=sns.displot(inp)\n    \n    plt.axvline(np.mean(inp),color='k',linestyle='dashed', linewidth=5)\n    _, max_ = plt.ylim()\n    plt.text(inp.mean()+inp.mean()/10, max_- max_ / 10, \"Mean: {:.2f}\".format(inp.mean()),\n            )\n    plt.title(str(n) + 'samples')\n    \n    return plt.figure\n\nplot_distribution(curve, 500)\nplot_distribution(curve2, 100)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T03:05:05.514326Z","iopub.execute_input":"2021-11-07T03:05:05.514900Z","iopub.status.idle":"2021-11-07T03:05:06.602489Z","shell.execute_reply.started":"2021-11-07T03:05:05.514851Z","shell.execute_reply":"2021-11-07T03:05:06.601832Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,10))\nsns.distplot(curve,hist=False, rug=True)\nsns.distplot(curve2,hist=False, rug=True)\nplt.axvline(np.mean(curve),color='green',linestyle='dashed',linewidth=3)\nplt.axvline(np.mean(curve2),color='orange',linestyle='dashed',linewidth=3)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-07T00:52:27.330221Z","iopub.execute_input":"2021-11-07T00:52:27.330551Z","iopub.status.idle":"2021-11-07T00:52:27.804480Z","shell.execute_reply.started":"2021-11-07T00:52:27.330517Z","shell.execute_reply":"2021-11-07T00:52:27.803439Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"del curve, curve2","metadata":{"execution":{"iopub.status.busy":"2021-11-07T03:05:17.080915Z","iopub.execute_input":"2021-11-07T03:05:17.081703Z","iopub.status.idle":"2021-11-07T03:05:17.085942Z","shell.execute_reply.started":"2021-11-07T03:05:17.081652Z","shell.execute_reply":"2021-11-07T03:05:17.085051Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X = train_sample.drop(columns=['id','target']).select_dtypes(include='float16')\ny = train_sample.target\n\n# feature selection\nX_train_fs, fs = select_features(X, y, mutual_info_classif)\n\n# what are scores for the features\n#for i in range(len(fs.scores_)):\n#\tprint('Feature %d: %f' % (i, fs.scores_[i]))\n# plot the scores\npyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\npyplot.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-07T03:05:49.383597Z","iopub.execute_input":"2021-11-07T03:05:49.383865Z","iopub.status.idle":"2021-11-07T03:06:08.743521Z","shell.execute_reply.started":"2021-11-07T03:05:49.383837Z","shell.execute_reply":"2021-11-07T03:06:08.742839Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#Feature list\nmi_list  = list() \nfor i in range(len(fs.scores_)):\n    if (fs.scores_[i] > 0):\n        mi_list.append(i)\n\nmi_data = train_sample[X.columns[mi_list]]","metadata":{"execution":{"iopub.status.busy":"2021-11-07T03:06:12.412655Z","iopub.execute_input":"2021-11-07T03:06:12.412913Z","iopub.status.idle":"2021-11-07T03:06:12.421257Z","shell.execute_reply.started":"2021-11-07T03:06:12.412885Z","shell.execute_reply":"2021-11-07T03:06:12.420253Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"mi_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-07T03:06:14.102764Z","iopub.execute_input":"2021-11-07T03:06:14.103492Z","iopub.status.idle":"2021-11-07T03:06:14.132216Z","shell.execute_reply.started":"2021-11-07T03:06:14.103442Z","shell.execute_reply":"2021-11-07T03:06:14.131533Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# load the dataset\nchi_train = train_sample.drop(columns=['id','target'])\nchi_train = chi_train.select_dtypes(include=['int8','int32'])\n\n# feature selection\nX_train_fx, fx = select_features(chi_train, y,chi2)\n\n# what are scores for the features\n#for i in range(len(fx.scores_)):\n#\tprint('Feature %d: %f' % (i, fx.scores_[i]))\n\n# plot the scores\npyplot.bar([i for i in range(len(fx.scores_))], fx.scores_)\npyplot.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-07T03:06:25.652639Z","iopub.execute_input":"2021-11-07T03:06:25.653410Z","iopub.status.idle":"2021-11-07T03:06:25.927302Z","shell.execute_reply.started":"2021-11-07T03:06:25.653370Z","shell.execute_reply":"2021-11-07T03:06:25.926535Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#Feature list\nchi2_list  = list() \nfor i in range(len(fx.scores_)):\n    if (fx.scores_[i] > 0.1):\n        chi2_list.append(i)\nchi_data = train_sample[chi_train.columns[chi2_list]]","metadata":{"execution":{"iopub.status.busy":"2021-11-07T03:06:33.421336Z","iopub.execute_input":"2021-11-07T03:06:33.421592Z","iopub.status.idle":"2021-11-07T03:06:33.426949Z","shell.execute_reply.started":"2021-11-07T03:06:33.421564Z","shell.execute_reply":"2021-11-07T03:06:33.426283Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"new_df = chi_data.join(mi_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T03:06:34.842572Z","iopub.execute_input":"2021-11-07T03:06:34.843117Z","iopub.status.idle":"2021-11-07T03:06:34.852470Z","shell.execute_reply.started":"2021-11-07T03:06:34.843079Z","shell.execute_reply":"2021-11-07T03:06:34.851638Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=10):\n    \n    dtrain_y = train_sample['target'].values\n    \n    if useTrainCV:\n        xgb_param = alg.get_xgb_params()\n        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain_y)\n        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n            metrics='auc', early_stopping_rounds=early_stopping_rounds)\n        alg.set_params(n_estimators=cvresult.shape[0])\n    \n    #Fit the algorithm on the data\n    alg.fit(dtrain[predictors], train_sample['target'],eval_metric='auc')\n        \n    #Predict training set:\n    dtrain_predictions = alg.predict(dtrain[predictors])\n    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n        \n    #Print model report:\n    print (\"\\nModel Report\")\n    print (\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain_y, dtrain_predictions))\n    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(train_sample['target'], dtrain_predprob))\n               \n    feat_imp = pd.Series(alg.get_booster().get_fscore()).sort_values(ascending=False)\n    feat_imp.plot(kind='bar', title='Feature Importances')\n    plt.ylabel('Feature Importance Score')\n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-07T03:06:36.013725Z","iopub.execute_input":"2021-11-07T03:06:36.014198Z","iopub.status.idle":"2021-11-07T03:06:36.025757Z","shell.execute_reply.started":"2021-11-07T03:06:36.014159Z","shell.execute_reply":"2021-11-07T03:06:36.025048Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"trainb = new_df.copy()\n\ntarget = 'target'\nIDcol = 'id'\npredictors = [x for x in trainb.columns if x not in ['target', 'id']]\n\nxgb1 = XGBClassifier(\n learning_rate =0.1,\n n_estimators=100,\n max_depth=5,\n min_child_weight=1,\n gamma=0,\n subsample=0.8,\n colsample_bytree=0.8,\n #objective= 'binary:logistic',\n nthread=4,\n scale_pos_weight=1,\n seed=27)\n\nmodelfit(xgb1, trainb, predictors)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-07T03:06:40.422845Z","iopub.execute_input":"2021-11-07T03:06:40.423377Z","iopub.status.idle":"2021-11-07T03:07:14.247530Z","shell.execute_reply.started":"2021-11-07T03:06:40.423337Z","shell.execute_reply":"2021-11-07T03:07:14.246790Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"X = train_sample.loc[:,new_df.columns]\nX_train, X_validation, y_train, y_validation = train_test_split(X, train_sample.target, test_size=0.25)\nxgb1.fit(X_train, y_train,eval_set=[(X_train, y_train), (X_validation, y_validation)], early_stopping_rounds=10) ","metadata":{"execution":{"iopub.status.busy":"2021-11-07T03:10:10.625793Z","iopub.execute_input":"2021-11-07T03:10:10.626400Z","iopub.status.idle":"2021-11-07T03:10:32.364600Z","shell.execute_reply.started":"2021-11-07T03:10:10.626362Z","shell.execute_reply":"2021-11-07T03:10:32.363851Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"results = xgb1.evals_result()\n\nplt.figure(figsize=(10,7))\nplt.plot(results['validation_0'][\"logloss\"], label=\"Training loss\")\nplt.plot(results['validation_1'][\"logloss\"], label=\"Validation loss\")\nplt.axvline(xgb1.best_ntree_limit, color=\"gray\", label=\"Optimal tree number\")\nplt.xlabel(\"Number of trees\")\nplt.ylabel(\"Loss\")\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-11-07T03:10:44.102673Z","iopub.execute_input":"2021-11-07T03:10:44.102926Z","iopub.status.idle":"2021-11-07T03:10:44.351677Z","shell.execute_reply.started":"2021-11-07T03:10:44.102899Z","shell.execute_reply":"2021-11-07T03:10:44.350988Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"bntl = xgb1.best_ntree_limit","metadata":{"execution":{"iopub.status.busy":"2021-11-07T02:05:11.850436Z","iopub.execute_input":"2021-11-07T02:05:11.852004Z","iopub.status.idle":"2021-11-07T02:05:11.856819Z","shell.execute_reply.started":"2021-11-07T02:05:11.851945Z","shell.execute_reply":"2021-11-07T02:05:11.855636Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"#Performing Coordinate Descent and tune depth and child weight\nparam_test1 = {\n 'max_depth':range(3,10,2),\n 'min_child_weight':range(1,8,2)\n}\n\ngsearch1 = GridSearchCV(estimator = XGBClassifier(seed=27), param_grid = param_test1, scoring='roc_auc',n_jobs=-1, cv=5)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T02:13:08.796345Z","iopub.execute_input":"2021-11-07T02:13:08.797370Z","iopub.status.idle":"2021-11-07T02:13:08.807940Z","shell.execute_reply.started":"2021-11-07T02:13:08.797305Z","shell.execute_reply":"2021-11-07T02:13:08.807069Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"gsearch1.fit(trainb[predictors],train_sample[target], verbose=2)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-07T03:15:34.543536Z","iopub.execute_input":"2021-11-07T03:15:34.543810Z","iopub.status.idle":"2021-11-07T03:15:34.547944Z","shell.execute_reply.started":"2021-11-07T03:15:34.543778Z","shell.execute_reply":"2021-11-07T03:15:34.546989Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"print(gsearch1.best_params_,gsearch1.best_score_)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T01:39:35.547620Z","iopub.status.idle":"2021-11-07T01:39:35.548083Z","shell.execute_reply.started":"2021-11-07T01:39:35.547879Z","shell.execute_reply":"2021-11-07T01:39:35.547902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Further tuning of depth and child weight\nparam_test2 = {\n 'max_depth':[2,3,4],\n 'min_child_weight':[4,5,6]\n}\ngsearch2 = GridSearchCV(estimator = XGBClassifier(seed=27), \n param_grid = param_test2, scoring='roc_auc',n_jobs=-1, cv=5)\n\ngsearch2 = GridSearchCV(estimator = XGBClassifier(seed=27), param_grid = param_test2, scoring='roc_auc',n_jobs=-1, cv=5)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gsearch2.fit(trainb[predictors],train_sample[target], verbose=2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gsearch2.best_params_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_test2b = {\n 'min_child_weight':[2,3,4,5]\n}\ngsearch2b = GridSearchCV(estimator = XGBClassifier(max_depth=2,seed=27), \n param_grid = param_test2b, scoring='roc_auc',n_jobs=4, cv=5)\n\ngsearch2b.fit(trainb[predictors],train_sample[target], verbose=2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gsearch2b.best_params_\ngsearch2b.best_score_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_test3 = {\n 'gamma':[i/10.0 for i in range(0,50)]\n}\ngsearch3 = GridSearchCV(estimator = XGBClassifier(max_depth=2,\n min_child_weight=4, seed=27), \n param_grid = param_test3, scoring='roc_auc',n_jobs=4, cv=5)\n\ngsearch3.fit(trainb[predictors],train_sample[target], verbose=2)\n#gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(gsearch3.best_params_, gsearch3.best_score_)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_test4 = {\n 'subsample':[i/10.0 for i in range(1,10)],\n 'colsample_bytree':[i/10.0 for i in range(1,10)]\n}\ngsearch4 = GridSearchCV(estimator = xgb.XGBClassifier(max_depth=2,\n min_child_weight=4, gamma=4.9, seed=27), \n param_grid = param_test4, scoring='roc_auc',n_jobs=4, cv=5)\ngsearch4.fit(trainb[predictors],train_sample[target], verbose=2)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(gsearch4.best_params_, gsearch4.best_score_)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_test5 = {\n 'subsample':[i/100.0 for i in range(85,95,1)],\n 'colsample_bytree':[i/100.0 for i in range(5,15,1)]\n}\n\ngsearch5 = GridSearchCV(estimator = XGBClassifier(max_depth=2,\n min_child_weight=4, gamma=4.9, seed=27), \n param_grid = param_test5, scoring='roc_auc',n_jobs=4, cv=5)\n\ngsearch5.fit(trainb[predictors],train_sample[target], verbose=2)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(gsearch5.best_params_, gsearch5.best_score_)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_test6 = {\n 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n}\n\ngsearch6 = GridSearchCV(estimator = XGBClassifier(max_depth=2,\n min_child_weight=4, gamma=4.9, colsample_bytree=0.14,subsample=0.88,seed=27), \n param_grid = param_test6, scoring='roc_auc',n_jobs=4, cv=5)\n\ngsearch6.fit(trainb[predictors],train_sample[target], verbose=2)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(gsearch6.best_params_, gsearch6.best_score_)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_test7 = {\n 'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05]\n}\n\ngsearch7 = GridSearchCV(estimator = XGBClassifier(max_depth=2,\n min_child_weight=4, gamma=4.9, colsample_bytree=0.14,subsample=0.88,seed=27), \n param_grid = param_test7, scoring='roc_auc',n_jobs=4, cv=5)\n\ngsearch7.fit(trainb[predictors],train_sample[target], verbose=2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(gsearch7.best_params_, gsearch7.best_score_)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Tuning the lamda reduces accuracy\n#param_test8 = {\n# 'reg_lambda':[0.1, 1.0, 5.0, 10.0, 50.0, 100.0]\n#}\n\n#gsearch8 = GridSearchCV(estimator = XGBClassifier(max_depth=2,\n# min_child_weight=4, gamma=4.9, colsample_bytree=0.95,\n# subsample=0.26,reg_alpha= 0.05,seed=27), \n# param_grid = param_test8, scoring='roc_auc',n_jobs=4, cv=5)\n\n#gsearch8.fit(trainb[predictors],train_sample[target], verbose=2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb1 = XGBClassifier(\n learning_rate = 0.01,\n n_estimators = 1000,\n max_depth=2,\n min_child_weight=4, \n gamma=4.9, \n colsample_bytree=0.95,\n subsample=0.26,\n reg_alpha= 0.05,\n seed=27)\n\nxgb1.fit(X_train, y_train,eval_set=[(X_train, y_train), (X_validation, y_validation)], early_stopping_rounds=10) \nresults = xgb1.evals_result()\n\nplt.figure(figsize=(10,7))\nplt.plot(results['validation_0'][\"logloss\"], label=\"Training loss\")\nplt.plot(results['validation_1'][\"logloss\"], label=\"Validation loss\")\nplt.axvline(xgb1.best_ntree_limit, color=\"gray\", label=\"Optimal tree number\")\nplt.xlabel(\"Number of trees\")\nplt.ylabel(\"Loss\")\nplt.legend()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-07T03:11:14.713911Z","iopub.execute_input":"2021-11-07T03:11:14.714638Z","iopub.status.idle":"2021-11-07T03:11:36.627874Z","shell.execute_reply.started":"2021-11-07T03:11:14.714600Z","shell.execute_reply":"2021-11-07T03:11:36.626954Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"cluster = LocalCluster(n_workers = 2)\nclient = Client(cluster)\n\ntrain_dask = dd.read_csv('../input/tabular-playground-series-oct-2021/train.csv')#,blocksize=64e6)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-07T03:15:58.912796Z","iopub.execute_input":"2021-11-07T03:15:58.913077Z","iopub.status.idle":"2021-11-07T03:16:00.323596Z","shell.execute_reply.started":"2021-11-07T03:15:58.913048Z","shell.execute_reply":"2021-11-07T03:16:00.322785Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train_dask.persist()\nX = train_dask.loc[:,new_df.columns]\ny = train_dask['target']\n\ndtrain = xgb.dask.DaskDMatrix(client,X,y)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T03:16:02.282713Z","iopub.execute_input":"2021-11-07T03:16:02.282971Z","iopub.status.idle":"2021-11-07T03:17:08.430690Z","shell.execute_reply.started":"2021-11-07T03:16:02.282941Z","shell.execute_reply":"2021-11-07T03:17:08.427848Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"params = {\n 'learning_rate' : 0.01,\n 'max_depth': 2,\n 'min_child_weight' : 4, \n 'gamma' : 4.9, \n 'colsample_bytree' : 0.95,\n 'subsample' : 0.26,\n 'reg_alpha': 0.05,\n 'nthread' : 4\n}\n\n# train the model\n#%%time \noutput = xgb.dask.train(\n    client, params, dtrain, num_boost_round = 1000,\n    evals=[(dtrain, 'accuracy'),(dtrain, 'auc')], early_stopping_rounds = 10\n)\n\nbooster = output['booster']  # booster is the trained model\nhistory = output['history']  # A dictionary containing evaluation \n","metadata":{"execution":{"iopub.status.busy":"2021-11-07T03:22:31.201040Z","iopub.execute_input":"2021-11-07T03:22:31.201651Z","iopub.status.idle":"2021-11-07T04:48:00.568080Z","shell.execute_reply.started":"2021-11-07T03:22:31.201616Z","shell.execute_reply":"2021-11-07T04:48:00.567197Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save\n#xgb1.save_model(\"my_xgboost.json\")\n\n# load\nnew_xgb = xgb.XGBClassifier()\nnew_xgb.load_model(\"./submission.csv/my_xgboost.json\")\n\n# check optimal number of trees of loaded model\n#new_xgb.best_ntree_limit\n","metadata":{"execution":{"iopub.status.busy":"2021-11-07T05:29:44.668215Z","iopub.execute_input":"2021-11-07T05:29:44.668667Z","iopub.status.idle":"2021-11-07T05:29:44.691781Z","shell.execute_reply.started":"2021-11-07T05:29:44.668629Z","shell.execute_reply":"2021-11-07T05:29:44.690772Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"test_dask = dd.read_csv('../input/tabular-playground-series-oct-2021/test.csv')\ntest_dask.persist()\n\ntest_id = test_dask['id']\ntest = test_dask.loc[:,new_df.columns]\n","metadata":{"execution":{"iopub.status.busy":"2021-11-07T04:58:02.303478Z","iopub.execute_input":"2021-11-07T04:58:02.304038Z","iopub.status.idle":"2021-11-07T04:58:43.551088Z","shell.execute_reply.started":"2021-11-07T04:58:02.303982Z","shell.execute_reply":"2021-11-07T04:58:43.550265Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"preds = xgb1.dask.predict_proba(client, output, test)\ny_test = preds.compute()\nsubmission = pd.DataFrame(list(zip(test_id, y_test)), columns =['id', 'target'])\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T05:25:49.398205Z","iopub.execute_input":"2021-11-07T05:25:49.398548Z","iopub.status.idle":"2021-11-07T05:25:49.420697Z","shell.execute_reply.started":"2021-11-07T05:25:49.398513Z","shell.execute_reply":"2021-11-07T05:25:49.418702Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"client.close()","metadata":{"execution":{"iopub.status.busy":"2021-11-07T04:59:26.943437Z","iopub.execute_input":"2021-11-07T04:59:26.944081Z","iopub.status.idle":"2021-11-07T04:59:26.967987Z","shell.execute_reply.started":"2021-11-07T04:59:26.944039Z","shell.execute_reply":"2021-11-07T04:59:26.967175Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}